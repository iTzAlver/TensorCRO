# TensorCRO substrates.

This is a Tensorflow-based implementation of the Coral Reef Optimization algorithm. The algorithm is implemented as a Tensorflow graph, which allows to run it in GPU and TPU. The algorithm is implemented as a set of substrate layers that can be combined with other algorithms such as Differential Evolution, Harmony Search and Random Search. The framework also allows to implement crossover operators as blxalpha, gaussian, uniform, masked and multipoint.

Crossovers:
1. [BLXAlpha](#blxalpha)
2. [Gaussian](#gaussian)
3. [Uniform](#uniform)
4. [Masked](#masked)
5. [Multipoint](#multipoint)
6. [Permutation](#permutation)

Algorithms:
1. [Differential Evolution](#differential)
2. [Harmony Search](#harmony)
3. [Random Search](#random)
4. [Estimation of Distribution](#eda)
5. [Piece loss/gain and energy loss/gain](#piece)
6. [Coordinate Descent](#cd)

Mutations:
1. [Gaussian](#gaussian)
2. [Uniform](#uniform)
3. [Poisson](#poisson)
4. [Truncated Uniform](#truncated)
5. [Gamma](#gamma)

Stateful Algorithms:

1. [Particle Swarm Optimization](#pso)
2. [Simulated Annealing](#sa)

# Crossovers:

## BLXAlpha <a name="blxalpha"></a>

The BLXAlphaCrossover method implements the BLX-Alpha crossover method. This method is a
generalization of the BLX crossover method, which is a generalization of the SBX crossover
method. The BLX-Alpha crossover method is a linear combination of the parents, with a
random alpha value between 0 and 1.
- :directives: Specifications of the parameters.
- :scale: Scale of the alpha value.

## Gaussian <a name="gaussian"></a>

The GaussianCrossover method implements a gaussian crossover. It is a selector between two parents,
where the probability of selecting a parent is given by a gaussian distribution. If the mean is 0.5 it is
equivalent to a uniform crossover.
- :mean: Mean of the gaussian.
- :stddev: Standard deviation of the gaussian.

## Uniform <a name="uniform"></a>

Uniform crossover is a genetic operator used to combine the information of two parents to generate a new
individual. The new individual is generated by randomly selecting a gene from each parent with equal
probability. This operator is used in the genetic algorithm to generate new individuals. It takes no
arguments.

## Masked <a name="masked"></a>

The MaskedCrossover method implements a mask for the crossover method. The mask is a list of 0s and 1s, where
0s indicate that the corresponding gene will be taken from the father, and 1s indicate that the corresponding
gene will be taken from the mother.
- :mask: Mask for the crossover method.

## Multipoint <a name="multipoint"></a>

The MultipointCrossover class implements a multipoint crossover. The points is a list of indices where
the points between the parents are swapped. The mask is applied to each parent, so the offspring will be
composed of the points of the first parent in the positions indicated by the mask, and the points of the
second parent in the positions not indicated by the mask.
- :points: List of indices where the points between the parents are swapped.

## Permutation <a name="permutation"></a>
The PermutationCrossover class implements a permutation crossover. The points is a list of indices where
the points between the parents are swapped. The mask is applied to each parent, so the offspring will be
composed of the points of the partents but the parameters of the sections are randomly permuted.

# Algorithms:

## Differential Evolution <a name="differential"></a>

Differential Search Crossover Operator implements the Differential Evolution algorithm. It is a crossover
operator that uses the following formula:

    x_i^{(k+1)} = x_i^{(k)} + F \cdot (x_{r_1}^{(k)} - x_{r_2}^{(k)}) \cdot \mathbb{1}_{\{r < CR\}}

Where :math:`F` is the band-width, :math:`CR` is the crossover probability and :math:`r` is a random
number between 0 and 1. The :math:`\mathbb{1}_{\{r < CR\}}` is a binary mask that is 1 if :math:`r < CR`
and 0 otherwise.

- :directives: Parameter specifications.
- :crossover_probability: Crossover probability of the algorithm (CR).
- :band_width: Band-width of the algorithm (F).

## Harmony Search <a name="harmony"></a>

Harmony Search Crossover Operator implements the Harmony Search algorithm. It is a crossover operator that uses
the following formula:


    x_i^{(k+1)} =

        x_i^{(k)}  if r_1 < HMC_{r}


        x_{r_2}^{(k)}  if r_1 >= HMC_{r} \text{ and } r_2 < PA_{r}


        x_i^{(k)} + BW \cdot (U_{min} - U_{max})  if  r_1 >= HMC_{r}  and  r_2 \geq PA_{r}

Where `BW` is the band-width, `HMC_{r}` is the Harmony Memory Consideration rate, `PA_{r}` is
the Pitch Adjustment rate and `r_1` and `r_2` are random numbers between 0 and 1.

- :directives: Parameter specifications.
- :hmc_r: The Harmony Memory Consideration rate (HMCR).
- :pa_r: The Pitch Adjustment rate (PAR).
- :bandwidth: The band-width (BW).

## Random Search <a name="random"></a>

This class implements the Random Search algorithm. It is a simple algorithm that generates random individuals
within the search space.
- :directives: Parameter specifications.
- :size: Size of the new population (float or int). If float, it is the percentage of the original
population and if int, it is the number of new individuals.

## Estimation of Distribution <a name="eda"></a>
This class implements the EstimationDistribution algorithm. It is a simple algorithm that generates random individuals
within the search space. It uses a Binomial distribution to generate new individuals.

- :directives: Parameter specifications.
- :init_prob: The initial probability of the binomial distribution.
- :lr: The learning rate of the binomial distribution.
- :proportion: The proportion of the population to be used to estimate the parameters.
- :top_select: The number of individuals to be used to estimate the parameters.
- :param dist: The distribution to be used. Binomial by default.

## Piece loss/gain and energy loss/gain <a name="piece"></a>
This class implements the Piece loss/gain and energy loss/gain algorithm. 
It is a simple algorithm that reduces or augments by a selected value randomly selected parameters of the population.
It adds or subtract alpha to random selected parameters.

- :directives: Parameter specifications.
- :alpha: Decrement value.
- :nmute: Number of parameters to reduce in mean.
- :loss: Whether to add or subtract the mutation.

## Energy reduction/augmentation <a name="piece"></a>
This class implements the Energy reduction/augmentation algorithm.
It is a simple algorithm that reduces or augments by a selected value randomly selected parameters of the population.
It multiply or divide alpha to random selected parameters.
It acts according to the cross-correlation of the parameters, as a gradient descent.

- :alpha: The initial value of the decrement.
- :likelihood: The initial likelihood of the individuals to be repeated.

## Coordinate Descent <a name="cd"></a>
This class implements the Coordinate Descent algorithm. It selects a random parameter and generates a new
population with all the possible values of that parameter, separated by a step size, epsilon.

- :directives: Parameter specifications.
- :epsilon: The increment of the parameters in the new search space.

# Mutations:

## Gaussian <a name="gaussian"></a>

The GaussianMutation method implements a gaussian mutation. It is a mutation where the new value is
given by a gaussian distribution.

## Uniform <a name="uniform"></a>

The UniformMutation method implements a uniform mutation. It is a mutation where the new value is
given by a uniform distribution.

## Poisson <a name="poisson"></a>

The PoissonMutation method implements a poisson mutation. It is a mutation where the new value is
given by a poisson distribution.

## Truncated Uniform <a name="truncated"></a>

The TruncatedUniformMutation method implements a truncated uniform mutation. It is a mutation where the new
value is given by a truncated uniform distribution.

## Gamma <a name="gamma"></a>

The GammaMutation method implements a gamma mutation. It is a mutation where the new value is
given by a gamma distribution.

# Stateful Algorithms:

## Particle Swarm Optimization <a name="pso"></a>

The Particle Swarm Optimization algorithm is a stateful algorithm. It is a crossover operator that uses
the following formula:

    Velocity (v) of individual i in the population (pop) in parameter (p) in epoch (t):
    v[i][p][t + 1] =    inertia          * v[i][p][t]
                      + social_factor    * (pop[i=best][p][t] - pop[i][p][t])
                      + cognition_factor * (pop[i][p][t=best] - pop[i][p][t])

Takes as input the following parameters:

- :directives: Parameter specifications.
- :inertia: Inertia of the algorithm (omega).
- :cognitive: Cognitive parameter of the algorithm (c1).
- :social: Social parameter of the algorithm (c2).
- :shape: Size of the PSO population (float or int). ALL STATEFUL SUBSTRATES MUST HAVE THIS PARAMETER.

## Simulated Annealing <a name="sa"></a>

The Simulated Annealing algorithm is a stateful algorithm. It is a mutation operator that uses
the following formula depending on the iteration number. It computes a temperature that is a threshold for a random
number that substitutes the current value with that exact probability. In TensorCRO, the temperature decreases only if
there is an alive coral in that spot.



# References:

1. [Coral Reef Optimization](https://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/2352_07744242.pdf)
2. [Differential Evolution](https://link.springer.com/article/10.1023/A:1008202821328)
3. [Harmony Search](https://www.researchgate.net/publication/314523255_Harmony_Search_Algorithm)
4. [Random Search](https://www.tandfonline.com/doi/abs/10.1080/01621459.1953.10501200)
5. [Particle Swarm Optimization](https://ieeexplore.ieee.org/document/488968)
6. [Simulated Annealing](https://www.mit.edu/~dbertsim/papers/Optimization/Simulated%20annealing.pdf)
7. [Estimation of Distribution](https://www.researchgate.net/publication/220529421_Estimation_of_Distribution_Algorithms_A_New_Tool_for_Evolutionary_Computation)